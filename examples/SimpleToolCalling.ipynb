{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "sys.path.append('../../aisuite')\n",
    "\n",
    "# Load from .env file if available\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aisuite as ai\n",
    "from aisuite.utils.tool_manager import ToolManager  # Import your ToolManager class\n",
    "\n",
    "client = ai.Client()\n",
    "tool_manager = ToolManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock tool functions.\n",
    "def get_current_temperature(location: str, unit: str):\n",
    "    # Simulate fetching temperature from an API\n",
    "    return {\"location\": location, \"unit\": unit, \"temperature\": 72}\n",
    "\n",
    "tool_manager.add_tool(get_current_temperature)\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the current temperature in San Francisco in Celsius?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool config: {'tools': [{'toolSpec': {'name': 'get_current_temperature', 'description': ' ', 'inputSchema': {'json': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': ''}, 'unit': {'type': 'string', 'description': ''}}, 'required': ['location', 'unit']}}}}]}\n",
      "Received tools specification: [{'type': 'function', 'function': {'name': 'get_current_temperature', 'description': ' ', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': ''}, 'unit': {'type': 'string', 'description': ''}}, 'required': ['location', 'unit']}}}]\n",
      "Formatted messages for Bedrock: [{'role': 'user', 'content': [{'text': 'What is the current temperature in San Francisco in Celsius?'}]}]\n",
      "Bedrock response for tool use: {'ResponseMetadata': {'RequestId': '18e97a0d-73e5-4794-8e5e-e8d6534a7d90', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 17 Nov 2024 06:21:37 GMT', 'content-type': 'application/json', 'content-length': '317', 'connection': 'keep-alive', 'x-amzn-requestid': '18e97a0d-73e5-4794-8e5e-e8d6534a7d90'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_POpRfVVZRKeGMKxXRemelQ', 'name': 'get_current_temperature', 'input': {'location': 'San Francisco', 'unit': 'Celsius'}}}]}}, 'stopReason': 'tool_use', 'usage': {'inputTokens': 354, 'outputTokens': 74, 'totalTokens': 428}, 'metrics': {'latencyMs': 565}}\n",
      "<aisuite.framework.choice.Choice object at 0x107032e40>\n"
     ]
    }
   ],
   "source": [
    "# model = anthropic:claude-3-5-sonnet-20240620\n",
    "# model = openai:gpt-4o\n",
    "# model = mistral:mistral-large-latest\n",
    "model = \"aws:anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "# model = \"groq:llama-3.1-70b-versatile\"\n",
    "response = client.chat.completions.create(\n",
    "    model=model, messages=messages, tools=tool_manager.tools())\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(content='', tool_calls=[ChatCompletionMessageToolCall(id='tooluse_POpRfVVZRKeGMKxXRemelQ', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"Celsius\"}', name='get_current_temperature'), type='function')], role='assistant', refusal=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '',\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': [ChatCompletionMessageToolCall(id='tooluse_POpRfVVZRKeGMKxXRemelQ', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"Celsius\"}', name='get_current_temperature'), type='function')]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(vars(response.choices[0].message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'tool', 'name': 'get_current_temperature', 'content': '{\"location\": \"San Francisco\", \"unit\": \"Celsius\", \"temperature\": 72}', 'tool_call_id': 'tooluse_POpRfVVZRKeGMKxXRemelQ'}]\n",
      "[{'role': 'user', 'content': 'What is the current temperature in San Francisco in Celsius?'}, Message(content='', tool_calls=[ChatCompletionMessageToolCall(id='tooluse_POpRfVVZRKeGMKxXRemelQ', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"Celsius\"}', name='get_current_temperature'), type='function')], role='assistant', refusal=None), {'role': 'tool', 'name': 'get_current_temperature', 'content': '{\"location\": \"San Francisco\", \"unit\": \"Celsius\", \"temperature\": 72}', 'tool_call_id': 'tooluse_POpRfVVZRKeGMKxXRemelQ'}]\n"
     ]
    }
   ],
   "source": [
    "if response.choices[0].message.tool_calls:\n",
    "    tool_results, result_as_message = tool_manager.execute_tool(response.choices[0].message.tool_calls)\n",
    "    print(result_as_message)\n",
    "    \n",
    "    messages.append(response.choices[0].message) # Model's function call message\n",
    "    messages.append(result_as_message[0])\n",
    "    print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool config: {'tools': [{'toolSpec': {'name': 'get_current_temperature', 'description': ' ', 'inputSchema': {'json': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': ''}, 'unit': {'type': 'string', 'description': ''}}, 'required': ['location', 'unit']}}}}]}\n",
      "Received tools specification: [{'type': 'function', 'function': {'name': 'get_current_temperature', 'description': ' ', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': ''}, 'unit': {'type': 'string', 'description': ''}}, 'required': ['location', 'unit']}}}]\n",
      "Formatted messages for Bedrock: [{'role': 'user', 'content': [{'text': 'What is the current temperature in San Francisco in Celsius?'}]}, {'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_POpRfVVZRKeGMKxXRemelQ', 'name': 'get_current_temperature', 'input': {'location': 'San Francisco', 'unit': 'Celsius'}}}]}, {'role': 'user', 'content': [{'toolResult': {'toolUseId': 'tooluse_POpRfVVZRKeGMKxXRemelQ', 'content': [{'json': {'location': 'San Francisco', 'unit': 'Celsius', 'temperature': 72}}]}}]}]\n",
      "Response: {'ResponseMetadata': {'RequestId': 'db370b8d-0d0a-4369-b7a5-179058a0d881', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 17 Nov 2024 06:21:47 GMT', 'content-type': 'application/json', 'content-length': '249', 'connection': 'keep-alive', 'x-amzn-requestid': 'db370b8d-0d0a-4369-b7a5-179058a0d881'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': 'The current temperature in San Francisco in Celsius is 72 degrees.'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 455, 'outputTokens': 19, 'totalTokens': 474}, 'metrics': {'latencyMs': 296}}\n",
      "The current temperature in San Francisco in Celsius is 72 degrees.\n"
     ]
    }
   ],
   "source": [
    "if response.choices[0].message.tool_calls:\n",
    "    # Send the tool response back to the model\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=model, messages=messages, tools=tool_manager.tools())\n",
    "\n",
    "    # Output the final response from the model\n",
    "    print(final_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of California?\"}]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"openai:gpt-4o\", messages=messages)\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
